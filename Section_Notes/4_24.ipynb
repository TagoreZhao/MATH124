{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "Suppose I want to minimize some function which has the form\n",
    "$$\n",
    "Q(w) = \\frac{1}{n}\\sum_{i=1}^n Q_i(w)\n",
    "$$\n",
    "Standard gradient descent would perform the update:\n",
    "$$\n",
    "w \\leftarrow w -\\eta \\nabla Q = w - \\frac{\\eta}{n}\\sum_{i=1}^n\\nabla Q_i(w)\n",
    "$$\n",
    "\n",
    "However, for some functions $Q_i$, it may be expensive to compute $\\sum_{i=1}^n\\nabla Q_i(w)$ over and over again. Instead, we can cheaply compute just one of the summand functions chosen at random and use this as an approximation for $\\nabla Q$ at each step. Since we want to make sure that we consider each of the loss functions, it often makes sense to loop through a random permutation of all the summands, instead of randomly choosing a new one each time.\n",
    "\n",
    "Stochastic Gradient Descent can be summarized as:\n",
    "- Choose an initial guess for $w$ and a learning rate/step size $\\eta$\n",
    "- Repeat until convergence:\n",
    "    - Randomly permute the indices $1,\\ldots,n$\n",
    "    - for i = $1,2,\\ldots, n$\n",
    "        - $w\\leftarrow w - \\eta\\nabla Q_i(w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Least Squares\n",
    "Suppose I have a bunch of 2-dimensional data $(x_1,y_1),\\ldots,(x_n,y_n)$ that takes output values of $z1,\\ldots,z_n$. I'd like to approximate my data with a plane, i.e. find the constants $a,b,c$ such that $\\hat{z}_i = a + bx_i + cy_i$ and the total mean squared error $\\frac{1}{n}\\sum_{i=1}^n (\\hat{z}_i - z_i)^2$ is minimized.\n",
    "\n",
    "1.) Using the language above, what is $w$ in this example? What is $Q(w)$ and what is $Q_i(w)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q(w)$ will be the sum of residual squared, $Q_{i}(w)$ is each single residual squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) What is $\\nabla Q_i(w)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the derivative of $Q_i(w)$ with respect to w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) The following code creates some data as described above. Implement Stochastic Gradient Descent to find the best-fit plane. Use the following implementation details:\n",
    "- initialize your starting guess as all zeros\n",
    "- consider the algorithm \"converged\" when your estimate of $w$ does not change by more than $10^{-12}$ between two consecutive (big) iterations\n",
    "- start with an initial learning rate of 0.2 and decrease your learning rate $\\eta$ by a factor of a half every 5 (big) iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Matrix{Float64}:\n",
       "  0.450669     0.591502\n",
       " -0.541145    -0.679773\n",
       " -0.770577    -0.797131\n",
       " -0.0518375    0.0818065\n",
       "  0.528255    -0.281314\n",
       "  0.913085    -0.751513\n",
       " -0.977598    -0.295611\n",
       "  0.0816963   -0.514981\n",
       "  0.0444324   -0.916009\n",
       " -0.202644    -0.842527\n",
       " -0.904149     0.57134\n",
       " -0.768417    -0.459681\n",
       "  0.840116    -0.916084\n",
       "  ⋮           \n",
       " -0.971552    -0.577191\n",
       "  0.448218     0.435247\n",
       " -0.349646     0.352153\n",
       " -0.809119    -0.645557\n",
       " -0.387887    -0.459428\n",
       " -0.00992128   0.359462\n",
       "  0.143819    -0.443921\n",
       "  0.12865     -0.425725\n",
       "  0.117638    -0.00303266\n",
       "  0.582055     0.156517\n",
       " -0.513545     0.691242\n",
       " -0.857894    -0.539451"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = 2*rand(Float64, (1000,2)) .- 1\n",
    "z = 1 .+ 5*xy[:, 1] .- 2*xy[:,2] .+ 0.1*randn(Float64, 1000)\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gradient_descent(f,initial)\n",
    "    \n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
